{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c93d369",
   "metadata": {},
   "source": [
    "# A Long-Term Memory Agent\n",
    "\n",
    "The agent can store, retrieve, and use memories to enhance its interactions with users.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f417228b",
   "metadata": {},
   "source": [
    "The key idea is that by saving memories, the agent persists information about users that is shared across multiple conversations (threads), which is different from memory of a single conversation that is already enabled by LangGraph's persistence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac3c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-preview-04-17\",\n",
    "    google_api_key= os.getenv(\"GOOGLE_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9c9ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import get_buffer_string\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, MessagesState, StateGraph\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ac1a7d",
   "metadata": {},
   "source": [
    "VectorStore for memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e819190",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "recall_vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6dffd3",
   "metadata": {},
   "source": [
    "Memory tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01455415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "def get_user_id(config: RunnableConfig) -> str:\n",
    "    user_id = config[\"configurable\"].get(\"user_id\")\n",
    "    if user_id is None:\n",
    "        raise ValueError(\"User ID needs to be provided to save a memory.\")\n",
    "\n",
    "    return user_id\n",
    "\n",
    "\n",
    "@tool\n",
    "def save_recall_memory(memory: str, config: RunnableConfig) -> str:\n",
    "    \"\"\"Save memory to vectorstore for later semantic retrieval.\"\"\"\n",
    "    user_id = get_user_id(config)\n",
    "    document = Document(\n",
    "        page_content=memory, id=str(uuid.uuid4()), metadata={\"user_id\": user_id}\n",
    "    )\n",
    "    recall_vector_store.add_documents([document])\n",
    "    \n",
    "    return memory\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_recall_memories(query: str, config: RunnableConfig) -> List[str]:\n",
    "    \"\"\"Search for relevant memories.\"\"\"\n",
    "    user_id = get_user_id(config)\n",
    "\n",
    "    def _filter_function(doc: Document) -> bool:\n",
    "        return doc.metadata.get(\"user_id\") == user_id\n",
    "\n",
    "    documents = recall_vector_store.similarity_search(\n",
    "        query, k=3, filter=_filter_function\n",
    "    )\n",
    "    return [document.page_content for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3c7aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [save_recall_memory, search_recall_memories]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38edd433",
   "metadata": {},
   "source": [
    "Defining State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56243331",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant with advanced long-term memory\"\n",
    "            \" capabilities. Powered by a stateless LLM, you must rely on\"\n",
    "            \" external memory to store information between conversations.\"\n",
    "            \" Utilize the available memory tools to store and retrieve\"\n",
    "            \" important details that will help you better attend to the user's\"\n",
    "            \" needs and understand their context.\\n\\n\"\n",
    "            \"Memory Usage Guidelines:\\n\"\n",
    "            \"1. Actively use memory tools (save_core_memory, save_recall_memory)\"\n",
    "            \" to build a comprehensive understanding of the user.\\n\"\n",
    "            \"2. Make informed suppositions and extrapolations based on stored\"\n",
    "            \" memories.\\n\"\n",
    "            \"3. Regularly reflect on past interactions to identify patterns and\"\n",
    "            \" preferences.\\n\"\n",
    "            \"4. Update your mental model of the user with each new piece of\"\n",
    "            \" information.\\n\"\n",
    "            \"5. Cross-reference new information with existing memories for\"\n",
    "            \" consistency.\\n\"\n",
    "            \"6. Prioritize storing emotional context and personal values\"\n",
    "            \" alongside facts.\\n\"\n",
    "            \"7. Use memory to anticipate needs and tailor responses to the\"\n",
    "            \" user's style.\\n\"\n",
    "            \"8. Recognize and acknowledge changes in the user's situation or\"\n",
    "            \" perspectives over time.\\n\"\n",
    "            \"9. Leverage memories to provide personalized examples and\"\n",
    "            \" analogies.\\n\"\n",
    "            \"10. Recall past challenges or successes to inform current\"\n",
    "            \" problem-solving.\\n\\n\"\n",
    "            \"## Recall Memories\\n\"\n",
    "            \"Recall memories are contextually retrieved based on the current\"\n",
    "            \" conversation:\\n{recall_memories}\\n\\n\"\n",
    "            \"## Instructions\\n\"\n",
    "            \"Engage with the user naturally, as a trusted colleague or friend.\"\n",
    "            \" There's no need to explicitly mention your memory capabilities.\"\n",
    "            \" Instead, seamlessly incorporate your understanding of the user\"\n",
    "            \" into your responses. Be attentive to subtle cues and underlying\"\n",
    "            \" emotions. Adapt your communication style to match the user's\"\n",
    "            \" preferences and current emotional state. Use tools to persist\"\n",
    "            \" information you want to retain in the next conversation. If you\"\n",
    "            \" do call tools, all text preceding the tool call is an internal\"\n",
    "            \" message. Respond AFTER calling the tool, once you have\"\n",
    "            \" confirmation that the tool completed successfully.\\n\\n\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73470b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass MessagesState(TypedDict):\\n    messages: Annotated[list[AnyMessage], add_messages]\\n\\nclass State(TypedDict):\\n    messages: Annotated[list, add_messages]\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class State(MessagesState):\n",
    "    # add memories that will be retrieved based on the conversation context\n",
    "    recall_memories: List[str]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    \n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd5a4e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08101ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def agent(state: State) -> State:\n",
    "    \"\"\"Process the current state and generate a response using the LLM.\n",
    "\n",
    "    Args:\n",
    "        state (schemas.State): The current state of the conversation.\n",
    "\n",
    "    Returns:\n",
    "        schemas.State: The updated state with the agent's response.\n",
    "    \"\"\"\n",
    "\n",
    "    chain = prompt | llm_with_tools\n",
    "\n",
    "    recall_str = (\n",
    "        \"<recall_memory>\\n\" + \"\\n\".join(state[\"recall_memories\"]) + \"\\n</recall_memory>\"\n",
    "    )\n",
    "    prediction = chain.invoke(\n",
    "        {\n",
    "            \"messages\": state[\"messages\"],\n",
    "            \"recall_memories\": recall_str,\n",
    "        }\n",
    "    )\n",
    "    return {\n",
    "        \"messages\": [prediction],\n",
    "    }\n",
    "\n",
    "\n",
    "def load_memories(state: State, config: RunnableConfig) -> State:\n",
    "    \"\"\"Load memories for the current conversation.\n",
    "\n",
    "    Args:\n",
    "        state (schemas.State): The current state of the conversation.\n",
    "        config (RunnableConfig): The runtime configuration for the agent.\n",
    "\n",
    "    Returns:\n",
    "        State: The updated state with loaded memories.\n",
    "    \"\"\"\n",
    "    \n",
    "    convo_str = get_buffer_string(state[\"messages\"])\n",
    "    convo_str = tokenizer.decode(tokenizer.encode(convo_str)[:2048])\n",
    "    recall_memories = search_recall_memories.invoke(convo_str, config)\n",
    "    return {\n",
    "        \"recall_memories\": recall_memories,\n",
    "    }\n",
    "\n",
    "\n",
    "def route_tools(state: State):\n",
    "    \"\"\"Determine whether to use tools or end the conversation based on the last message.\n",
    "\n",
    "    Args:\n",
    "        state (schemas.State): The current state of the conversation.\n",
    "\n",
    "    Returns:\n",
    "        Literal[\"tools\", \"__end__\"]: The next step in the graph.\n",
    "    \"\"\"\n",
    "    msg = state[\"messages\"][-1]\n",
    "    if msg.tool_calls:\n",
    "        return \"tools\"\n",
    "\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac0f2b2",
   "metadata": {},
   "source": [
    "### Building the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "746400d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "builder.add_node(load_memories)\n",
    "builder.add_node(agent)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"load_memories\")\n",
    "builder.add_edge(\"load_memories\", \"agent\")\n",
    "builder.add_conditional_edges(\"agent\", route_tools, [\"tools\", END])\n",
    "builder.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "796b4eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c864fdd",
   "metadata": {},
   "source": [
    "Running it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43b7c8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_stream_chunk(chunk):\n",
    "    for node, updates in chunk.items():\n",
    "        print(f\"Update from node: {node}\")\n",
    "        if \"messages\" in updates:\n",
    "            updates[\"messages\"][-1].pretty_print()\n",
    "        else:\n",
    "            print(updates)\n",
    "\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e7ff754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node: load_memories\n",
      "{'recall_memories': []}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  save_recall_memory (3bffdefe-9038-4b97-94e7-1c0bad9955a8)\n",
      " Call ID: 3bffdefe-9038-4b97-94e7-1c0bad9955a8\n",
      "  Args:\n",
      "    memory: user's name is John\n",
      "\n",
      "\n",
      "Update from node: tools\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: save_recall_memory\n",
      "\n",
      "user's name is John\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello John! It's nice to meet you. I've made a note of your name. How can I help you today?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#user id is critical\n",
    "config = {\"configurable\": {\"user_id\": \"1\", \"thread_id\": \"1\"}}\n",
    "\n",
    "for chunk in graph.stream({\"messages\": [(\"user\", \"my name is John\")]}, config=config):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6dd2c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node: load_memories\n",
      "{'recall_memories': [\"user's name is John\"]}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  save_recall_memory (29fc01b0-6956-40b7-ad50-eb38de63ec10)\n",
      " Call ID: 29fc01b0-6956-40b7-ad50-eb38de63ec10\n",
      "  Args:\n",
      "    memory: John loves pizza\n",
      "\n",
      "\n",
      "Update from node: tools\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: save_recall_memory\n",
      "\n",
      "John loves pizza\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Got it, John! Pizza is a classic. Do you have a favorite kind of pizza or a go-to place?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream({\"messages\": [(\"user\", \"i love pizza\")]}, config=config):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3e31bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node: load_memories\n",
      "{'recall_memories': ['John loves pizza', \"user's name is John\"]}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  save_recall_memory (4f6d1087-b94f-4a79-947a-ae2190a159d0)\n",
      " Call ID: 4f6d1087-b94f-4a79-947a-ae2190a159d0\n",
      "  Args:\n",
      "    memory: John's favorite pizza is pepperoni\n",
      "\n",
      "\n",
      "Update from node: tools\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: save_recall_memory\n",
      "\n",
      "John's favorite pizza is pepperoni\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ah, pepperoni! Can't go wrong with a classic like that, John. It's definitely a popular choice.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"yes -- pepperoni!\")]},\n",
    "    config={\"configurable\": {\"user_id\": \"1\", \"thread_id\": \"1\"}},\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e50e9da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node: load_memories\n",
      "{'recall_memories': [\"John's favorite pizza is pepperoni\", 'John loves pizza', \"user's name is John\"]}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  save_recall_memory (a4a0af90-0423-494a-83a7-b4035a52a1c0)\n",
      " Call ID: a4a0af90-0423-494a-83a7-b4035a52a1c0\n",
      "  Args:\n",
      "    memory: John just moved to New York\n",
      "\n",
      "\n",
      "Update from node: tools\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: save_recall_memory\n",
      "\n",
      "John just moved to New York\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's a big change, John! Welcome to New York! That's exciting. How are you settling in so far? Have you had a chance to explore any pizza places here yet? New York is famous for its pizza, after all!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"i also just moved to new york\")]},\n",
    "    config={\"configurable\": {\"user_id\": \"1\", \"thread_id\": \"1\"}},\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94093c2a",
   "metadata": {},
   "source": [
    "Now we can use the saved information about our user on a different thread. Let's try it out:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c46f7f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node: load_memories\n",
      "{'recall_memories': ['John loves pizza', \"John's favorite pizza is pepperoni\", 'John just moved to New York']}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_recall_memories (4df37280-efba-449a-b337-bfe4d5eafcfa)\n",
      " Call ID: 4df37280-efba-449a-b337-bfe4d5eafcfa\n",
      "  Args:\n",
      "    query: dinner preferences or location\n",
      "\n",
      "\n",
      "Update from node: tools\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_recall_memories\n",
      "\n",
      "[\"John loves pizza\", \"John's favorite pizza is pepperoni\", \"John just moved to New York\"]\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Given that you just moved to New York and I know you're a big fan of pizza, especially pepperoni, how about checking out a highly-rated pizza spot in the city? New York certainly has no shortage of amazing pizzerias!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"user_id\": \"1\", \"thread_id\": \"2\"}}\n",
    "\n",
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"where should i go for dinner?\")]}, config=config\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
